{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61246,"databundleVersionId":6604167,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-11T16:11:36.739412Z","iopub.execute_input":"2023-12-11T16:11:36.739883Z","iopub.status.idle":"2023-12-11T16:11:36.749056Z","shell.execute_reply.started":"2023-12-11T16:11:36.739843Z","shell.execute_reply":"2023-12-11T16:11:36.747916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dummy regressor for first submission\n'''\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\ndf = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')\n\nX = df.drop(columns=['total_amount'])\n\ny = df['total_amount']\ndummy_regressor = DummyRegressor(strategy='mean')  # base line model for taxi fare prediction, we can also use median\n\ndummy_regressor.fit(X,y)\n\nxtest=pd.read_csv(\"/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv\")\nypdc = dummy_regressor.predict(xtest)\nprint(ypdc)'''","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:42:33.518793Z","iopub.execute_input":"2023-12-10T18:42:33.519235Z","iopub.status.idle":"2023-12-10T18:42:35.972522Z","shell.execute_reply.started":"2023-12-10T18:42:33.519200Z","shell.execute_reply":"2023-12-10T18:42:35.971596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first submission\n'''\nsubmission = pd.DataFrame(columns = [\"ID\",\"total_amount\"])\nsubmission[\"ID\"] = [i for i in range(1,len(ypdc)+1)]\nsubmission[\"total_amount\"] = ypdc\nsubmission.to_csv('submission.csv',index=False)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:36:59.668215Z","iopub.execute_input":"2023-10-12T14:36:59.669319Z","iopub.status.idle":"2023-10-12T14:36:59.828516Z","shell.execute_reply.started":"2023-10-12T14:36:59.669275Z","shell.execute_reply":"2023-10-12T14:36:59.827714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **EXPLORATORY DATA ANALYSIS**","metadata":{}},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv')\ndf_train=pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')\n\n#information and related statistics about the test dataset given\n# ANSI escape codes for bold text\nstats = \"\\033[1mStats:\\033[0m\"\n\nprint(stats)\ndf_test.head()\ndf_test.info()\ndf_test.describe()\n#to be predicted: total_amount","metadata":{"execution":{"iopub.status.busy":"2023-12-11T16:11:44.193357Z","iopub.execute_input":"2023-12-11T16:11:44.193839Z","iopub.status.idle":"2023-12-11T16:11:45.423615Z","shell.execute_reply.started":"2023-12-11T16:11:44.193795Z","shell.execute_reply":"2023-12-11T16:11:45.422332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#information and stats about the training dataset given\nstats = \"\\033[1mStats:\\033[0m\"\n\nprint(stats)\ndf_train.head()\ndf_train.info()\ndf_train.describe()\n\n#target variable: total_amount","metadata":{"execution":{"iopub.status.busy":"2023-12-11T16:11:51.550773Z","iopub.execute_input":"2023-12-11T16:11:51.551223Z","iopub.status.idle":"2023-12-11T16:11:51.742417Z","shell.execute_reply.started":"2023-12-11T16:11:51.551184Z","shell.execute_reply":"2023-12-11T16:11:51.741129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot for trip distance vs total amount  (we can see certain outliers)\n#and payment type vs total amount\nimport matplotlib.pyplot as plot\nimport seaborn as sea\n\nsea.scatterplot(x='trip_distance', y='total_amount', data=df_train)\nplot.title('Scatter Plot (trip_distance vs total_amount)')  #title\nplot.show()\n\nsea.scatterplot(x='payment_type', y='total_amount', data=df_train)\nplot.title('Scatter Plot (payment_type vs total_amount)')    #title\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T16:11:57.972842Z","iopub.execute_input":"2023-12-11T16:11:57.973310Z","iopub.status.idle":"2023-12-11T16:11:59.396671Z","shell.execute_reply.started":"2023-12-11T16:11:57.973272Z","shell.execute_reply":"2023-12-11T16:11:59.395397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is a count plot, for categorical columns (with value_counts())\n\ncategorical_columns = ['VendorID', 'payment_type', 'store_and_fwd_flag']\n\nfor col in categorical_columns:\n    sea.countplot(x=col, data=df_train)  \n    plot.title(f'Count Plot ({col})')    \n    plot.show()\n    value_counts = df_train[col].value_counts()   #gives the value counts for each category \n    print(f'Value counts for {col}:')\n    print(value_counts)\n    print('\\n' + '=============================================' + '\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T19:38:45.572051Z","iopub.execute_input":"2023-12-10T19:38:45.572518Z","iopub.status.idle":"2023-12-10T19:38:46.912742Z","shell.execute_reply.started":"2023-12-10T19:38:45.572481Z","shell.execute_reply":"2023-12-10T19:38:46.911345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is a simple visualization for total amount and its occurrences (with kde)\n\nplot.figure(figsize=(12, 6))                       #canvas size\nsea.histplot(df_train['total_amount'], kde=True)     #automatically trains the data to fit in the range - kde gives us an estimation line\nplot.title('Training Data (total_amount)')   #title of the graph\nplot.xlabel('total_amount')                  #x axis\nplot.ylabel('frequency')                     #y axis\nplot.show()\n\nprint('v ========== With just KDE ============= v')\n\nsea.kdeplot(df_train['total_amount'])\nplot.title('Kernel Density Estimate (total_amount)')  #title\nplot.xlabel('total_amount')   #x axis\nplot.ylabel('density')      #y axis\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T19:47:03.678872Z","iopub.execute_input":"2023-12-10T19:47:03.679280Z","iopub.status.idle":"2023-12-10T19:47:10.306699Z","shell.execute_reply.started":"2023-12-10T19:47:03.679248Z","shell.execute_reply":"2023-12-10T19:47:10.305461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#boxplot for understanding the distribution\n#and detecting outliers\n\nsea.boxplot(x='passenger_count', y='total_amount', data=df_train)\nplot.title('Box Plot (total_amount vs passenger_count)')\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T19:49:07.568749Z","iopub.execute_input":"2023-12-10T19:49:07.569211Z","iopub.status.idle":"2023-12-10T19:49:08.062025Z","shell.execute_reply.started":"2023-12-10T19:49:07.569179Z","shell.execute_reply":"2023-12-10T19:49:08.060875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pair plot for passenger_count, trip_distance, extra, tip_amount, total_amount\nsample_df_train = df_train.sample(n=1000, random_state=42)       #random sample of 1000 rows for quicker plotting\n\nsea.pairplot(sample_df_train[['passenger_count', 'trip_distance', 'extra', 'tip_amount', 'total_amount']])\nplot.suptitle('Pair Plot of Selected Variables', y='1.02')  # Adjust title position\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T20:05:57.145029Z","iopub.execute_input":"2023-12-10T20:05:57.145554Z","iopub.status.idle":"2023-12-10T20:06:06.393240Z","shell.execute_reply.started":"2023-12-10T20:05:57.145518Z","shell.execute_reply":"2023-12-10T20:06:06.392002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation matrix (typically created for columns with numerical values)\nnum_col = df_train.select_dtypes(include=['number']).columns    #columns with numerical values only\ncorrelation_matrix = df_train[num_col].corr()\n\nplot.figure(figsize=(12,10))\nsea.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")  #annot=true gives the numbers, coolwarm the color range and fmt the decimal range\nplot.title('Correlation Heatmap')     #correlation coefficient can help us determine the strength and direction of linear relation bw 2 vars\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T20:12:07.071494Z","iopub.execute_input":"2023-12-10T20:12:07.071952Z","iopub.status.idle":"2023-12-10T20:12:08.213608Z","shell.execute_reply.started":"2023-12-10T20:12:07.071918Z","shell.execute_reply":"2023-12-10T20:12:08.211557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **MODELS**","metadata":{}},{"cell_type":"markdown","source":"In this competition, I have chosen three models to work upon: (in case, the 3 models don't fit satisfactorily, I may add some additional models):\n1. Linear Regression Model\n2. Gradient Boosting Regression Model\n3. K-Nearest Neighbours (KNN) Regression Model\n\nFirstly I hyperparameter tune both linear and gradient boosting model so that the models can work optimally. (I chose to do hyperparameter tuning of KNN after I had run both the initial models)\nAs to why I chose these models:\n\n1) Linear Regression Model\n\nI wanted to start with a simple baseline model, and pick the pace up from there. Linear regression works perfectly as my first model, since the relationship between the input variables and output is expressed a linear equation, which is simple to understand. It particularly performs well when the independent and dependent variables and approximately linear. I can compare this simple benchmark model with the more complex model I plan to use later on. This model is also efficient and can be quickly trained on even large datasets.\n\n2) Gradient boosting regressiono model\n\nThis model is relatively complex, and therefore it can model complex, non- linear data. It is capable of capturing intricate patterns. Its also robust to outliers in the data. This model also allows for much fine hyperparameter tuning, which can lead to more accuracy in predictions. Parameters like learning rate, estimators etc, to achieve desired balance. Despite its advauntages it may require careful hyper tuning and could be computationally more expensive to simpler models like linear regression. \n\n3) KNN Regression Model\n\nI wanted to try out one more model which was relatively simpler and easy to implement, but can also, unlike linear regression, not assume linear relationship between input features and target variable. The localized approach of KNN model can help us identify local patterns and variations in the data. It is suitable for apps where underlying pattern may evolve, since it makes no assumptions about the distribution of data. ","metadata":{}},{"cell_type":"markdown","source":"*Hyperparameters calculation for Linear Regression and Gradient Boosting.*","metadata":{}},{"cell_type":"code","source":"'''\n#hyperparameter for the dataset (I have used linear regression, gradient boosting and KNN regressors, but the\n#hyperparameter traning for KNN is done after linear and gradient boosting regressions)\n\nimport pandas as pd           #data manipulation and analysis\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import GradientBoostingRegressor     #used gradient boosting\nfrom sklearn.linear_model import LinearRegression     #used linear regression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n\n#loading the training data\ndf_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')\n\n#data Preprocessing\nnum_cols = df_train.select_dtypes(include=['number']).columns        #find all the numerical columns and store them\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].mean())   #fill the missing values with their mean\n#convert 'tpep_pickup_datetime' to datetime format:\ndf_train['tpep_pickup_datetime'] = pd.to_datetime(df_train['tpep_pickup_datetime'])  \n#creates new features: 'hour_of_day' and 'day_of_week' based on the pickup time.\ndf_train['hour_of_day'] = df_train['tpep_pickup_datetime'].dt.hour\ndf_train['day_of_week'] = df_train['tpep_pickup_datetime'].dt.dayofweek\ndf_train = pd.get_dummies(df_train, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n#here  we split the data into feature x and target y\nX = df_train.drop(columns=['total_amount', 'tpep_pickup_datetime', 'tpep_dropoff_datetime'])\ny = df_train['total_amount']\n\n#data gets split into training and validation sets using 80-20 split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#models used (liner and gradient regression)\nmodels = {\n    'linear regression': (LinearRegression(), {'fit_intercept': [True, False]}),\n    'gradient boosting': (GradientBoostingRegressor(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]})\n}\n\n# model iteration, perform hyperparameter tuning using gridsearchcv\nfor model_name, (model, param_grid) in models.items():\n    print(f\"\\nhyperparameter tuning {model_name}...\")\n    \n    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n    grid_search.fit(X_train, y_train)\n    \n    # best hyper parameters\n    best_params = grid_search.best_params_\n    print(f\"best hyperparameters: {best_params}\")\n    \n    # validation set evaluation (common metric for regression tasks)\n    val_predictions = grid_search.best_estimator_.predict(X_val)\n    mse = mean_squared_error(y_val, val_predictions)\n    rmse = mse**0.5\n    print(f\"Root mean squared error (RMSE) on Validation Set: {rmse}\")\n\n    # cross validation (5-fold) prints the cross validated RMSE for each model\n    c_val_results = cross_val_score(grid_search.best_estimator_, X, y, scoring='neg_mean_squared_error', cv=5)\n    c_val_rmse = (-c_val_results.mean())**0.5\n    print(f\"Cross-validation RMSE: {c_val_rmse}\")\n    '''","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:09:45.441498Z","iopub.execute_input":"2023-12-14T22:09:45.441997Z","iopub.status.idle":"2023-12-14T22:23:30.860817Z","shell.execute_reply.started":"2023-12-14T22:09:45.441948Z","shell.execute_reply":"2023-12-14T22:23:30.859338Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\nHyperparameter tuning for linear regression...\nBest Hyperparameters: {'fit_intercept': True}\nRoot Mean Squared Error (RMSE) on Validation Set: 13.444026265491303\nCross-Validation RMSE: 13.358983536025578\n\nHyperparameter tuning for gradient boosting...\nBest Hyperparameters: {'learning_rate': 0.2, 'n_estimators': 200}\nRoot Mean Squared Error (RMSE) on Validation Set: 5.535505400161676\nCross-Validation RMSE: 6.25698315049157\n","output_type":"stream"}]},{"cell_type":"markdown","source":"hyperparameter tuning linear regression...\nbest hyperparameters: {'fit_intercept': True}\nRoot mean squared error (RMSE) on Validation Set: 13.444026265491303\nCross-validation RMSE: 13.358983536025578\n\nhyperparameter tuning gradient boosting...\nbest hyperparameters: {'learning_rate': 0.2, 'n_estimators': 200}\nRoot mean squared error (RMSE) on Validation Set: 5.535505400161676\nCross-validation RMSE: 6.25698315049157","metadata":{}},{"cell_type":"markdown","source":"***Linear Regression :***","metadata":{}},{"cell_type":"code","source":"#linear regression\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# loading the training dataset\ndf_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T23:15:30.590148Z","iopub.execute_input":"2023-12-14T23:15:30.590661Z","iopub.status.idle":"2023-12-14T23:15:31.264611Z","shell.execute_reply.started":"2023-12-14T23:15:30.590625Z","shell.execute_reply":"2023-12-14T23:15:31.262858Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# data preprocessing and filling the missing values with the mean\nnum_cols = df_train.select_dtypes(include=['number']).columns\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].mean())\n\n# feature engineering (similar to the one hyperparameter tuning) \n#convert 'tpep_pickup_datetime' to datetime format and create new features based on the pickup time\ndf_train['tpep_pickup_datetime'] = pd.to_datetime(df_train['tpep_pickup_datetime'])\ndf_train['hour_of_day'] = df_train['tpep_pickup_datetime'].dt.hour\ndf_train['day_of_week'] = df_train['tpep_pickup_datetime'].dt.dayofweek\n\n# encoding categorical variables\ndf_train = pd.get_dummies(df_train, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T23:15:34.928142Z","iopub.execute_input":"2023-12-14T23:15:34.928619Z","iopub.status.idle":"2023-12-14T23:15:35.214443Z","shell.execute_reply.started":"2023-12-14T23:15:34.928568Z","shell.execute_reply":"2023-12-14T23:15:35.213112Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into features x and target y\nX_train = df_train.drop(columns=['total_amount', 'tpep_pickup_datetime', 'tpep_dropoff_datetime'])\ny_train = df_train['total_amount']\n\n# training and initializing our model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# predictions on the train\npredictions_train = model.predict(X_train)\n\n# evaluating the r2 score\nr2_train = r2_score(y_train, predictions_train)\nprint(f\"r2 score on training set: {r2_train}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T23:15:39.726113Z","iopub.execute_input":"2023-12-14T23:15:39.726612Z","iopub.status.idle":"2023-12-14T23:15:40.064781Z","shell.execute_reply.started":"2023-12-14T23:15:39.726577Z","shell.execute_reply":"2023-12-14T23:15:40.062854Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"r2 score on training set: 0.724924576235809\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading test data\ndf_test = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv')\n\n# data preprocessing and filling the missing values with the mean\nnum_cols_test = df_test.select_dtypes(include=['number']).columns\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].mean())\n\n# feature engineering (similar to the one hyperparameter tuning) \n#convert 'tpep_pickup_datetime' to datetime format and create new features based on the pickup time\ndf_test['tpep_pickup_datetime'] = pd.to_datetime(df_test['tpep_pickup_datetime'])\ndf_test['hour_of_day'] = df_test['tpep_pickup_datetime'].dt.hour\ndf_test['day_of_week'] = df_test['tpep_pickup_datetime'].dt.dayofweek\ndf_test = pd.get_dummies(df_test, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n#the same columns as used for training\nX_test = df_test[X_train.columns]\n\n# making predictions on the data set\npredictions_test = model.predict(X_test)\n\n# dataframe for the predictions\nids_test = pd.Series(range(1, len(predictions_test) + 1))\ndf_predictions = pd.DataFrame({'ID': ids_test, 'total_amount': predictions_test})","metadata":{"execution":{"iopub.status.busy":"2023-12-14T23:15:59.768631Z","iopub.execute_input":"2023-12-14T23:15:59.769118Z","iopub.status.idle":"2023-12-14T23:16:00.074299Z","shell.execute_reply.started":"2023-12-14T23:15:59.769082Z","shell.execute_reply":"2023-12-14T23:16:00.071891Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"'''\n# SAVING TO SUBMISSION.CSV\ndf_predictions.to_csv('submission.csv', index=False)'''","metadata":{"execution":{"iopub.status.busy":"2023-12-14T23:16:03.873191Z","iopub.execute_input":"2023-12-14T23:16:03.873658Z","iopub.status.idle":"2023-12-14T23:16:04.097722Z","shell.execute_reply.started":"2023-12-14T23:16:03.873618Z","shell.execute_reply":"2023-12-14T23:16:04.096416Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"r2 score on training set: 0.724924576235809 (LINEAR REGRESSION)\n\nScore in the competition: 0.7067","metadata":{}},{"cell_type":"markdown","source":"***GRADIENT BOOSTING REGRESSION***","metadata":{}},{"cell_type":"code","source":"#gradient boosting regression\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\n\n# loading the training data\ndf_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T10:25:09.881877Z","iopub.execute_input":"2023-12-15T10:25:09.882310Z","iopub.status.idle":"2023-12-15T10:25:12.703117Z","shell.execute_reply.started":"2023-12-15T10:25:09.882274Z","shell.execute_reply":"2023-12-15T10:25:12.701848Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# data preprocessing and filling the missing values with the mean\nnum_cols = df_train.select_dtypes(include=['number']).columns\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].mean())\n\n# feature engineering (similar to the one hyperparameter tuning) \n#convert 'tpep_pickup_datetime' to datetime format and create new features based on the pickup time\ndf_train['tpep_pickup_datetime'] = pd.to_datetime(df_train['tpep_pickup_datetime'])\ndf_train['hour_of_day'] = df_train['tpep_pickup_datetime'].dt.hour\ndf_train['day_of_week'] = df_train['tpep_pickup_datetime'].dt.dayofweek\n\n# encoding categorical vars\ndf_train = pd.get_dummies(df_train, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T10:25:15.408887Z","iopub.execute_input":"2023-12-15T10:25:15.409295Z","iopub.status.idle":"2023-12-15T10:25:15.748008Z","shell.execute_reply.started":"2023-12-15T10:25:15.409263Z","shell.execute_reply":"2023-12-15T10:25:15.746635Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# splitted data into features x and target y\nX_train = df_train.drop(columns=['total_amount', 'tpep_pickup_datetime', 'tpep_dropoff_datetime'])\ny_train = df_train['total_amount']\n\n# training and initializing the training moddel\nmodel = GradientBoostingRegressor(learning_rate=0.2,n_estimators=200, random_state=42)\nmodel.fit(X_train, y_train)\n\n# predictions on the training set\npredictions_train = model.predict(X_train)\n\n# evaluating the model on r2 score\nr2_train = r2_score(y_train, predictions_train)\nprint(f\"r2 score on training set is : {r2_train}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T10:25:21.604358Z","iopub.execute_input":"2023-12-15T10:25:21.604810Z","iopub.status.idle":"2023-12-15T10:26:30.893168Z","shell.execute_reply.started":"2023-12-15T10:25:21.604775Z","shell.execute_reply":"2023-12-15T10:26:30.891249Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"r2 score on training set is : 0.9577643163570861\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading the test data\ndf_test = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv')\n\n# data preprocessing and filling the missing values with the mean\nnum_cols_test = df_test.select_dtypes(include=['number']).columns\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].mean())\n\n# feature engg - test data\ndf_test['tpep_pickup_datetime'] = pd.to_datetime(df_test['tpep_pickup_datetime'])\ndf_test['hour_of_day'] = df_test['tpep_pickup_datetime'].dt.hour\ndf_test['day_of_week'] = df_test['tpep_pickup_datetime'].dt.dayofweek\ndf_test = pd.get_dummies(df_test, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n# same columns as used for training\nX_test = df_test[X_train.columns]\n\n# predictions on the test set\npredictions_test = model.predict(X_test)\n\n# data frame for predictions\ntest_ids = pd.Series(range(1, len(predictions_test) + 1))\ndf_predictions_final = pd.DataFrame({'ID': test_ids, 'total_amount': predictions_test})","metadata":{"execution":{"iopub.status.busy":"2023-12-15T10:26:45.847537Z","iopub.execute_input":"2023-12-15T10:26:45.847958Z","iopub.status.idle":"2023-12-15T10:26:46.300011Z","shell.execute_reply.started":"2023-12-15T10:26:45.847925Z","shell.execute_reply":"2023-12-15T10:26:46.298769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_predictions_final.head\ndf_predictions_final.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T10:31:00.038367Z","iopub.execute_input":"2023-12-15T10:31:00.039013Z","iopub.status.idle":"2023-12-15T10:31:00.255678Z","shell.execute_reply.started":"2023-12-15T10:31:00.038967Z","shell.execute_reply":"2023-12-15T10:31:00.254637Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"r2 score on training set is : 0.9577643163570861 (GRADIENT BOOSTING)\n\nScore in the competition: 0.94461","metadata":{}},{"cell_type":"markdown","source":"***HYPERPARAMETER TUNING FOR KNN REGRESSOR***","metadata":{}},{"cell_type":"code","source":"'''#hyperparameter tuning for knn regressor\n# importing necessary libraries, including Pandas for data manipulation, \n# scikit-learn for machine learning, and specific modules for K-Nearest Neighbors regression.\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import make_scorer, r2_score\n\n# loading the traning dataset from csv file into pandas dataframe\ndf_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')\n\n# data preprocessing\n# identifying numeric columns and fill missing values in those columns with their mean.\nnum_cols = df_train.select_dtypes(include=['number']).columns\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].mean())\n\n# feature engineering\n# converting the 'tpep_pickup_datetime' column to datetime format and extract the hour and day of the week as new features.\ndf_train['tpep_pickup_datetime'] = pd.to_datetime(df_train['tpep_pickup_datetime'])\ndf_train['hour_of_day'] = df_train['tpep_pickup_datetime'].dt.hour\ndf_train['day_of_week'] = df_train['tpep_pickup_datetime'].dt.dayofweek\n\n# performing one-hot encoding on categorical variables ('store_and_fwd_flag', 'payment_type').\ndf_train = pd.get_dummies(df_train, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n# splitting the data into features (X_train) and the target variable (y_train).\nX_train = df_train.drop(columns=['total_amount', 'tpep_pickup_datetime', 'tpep_dropoff_datetime'])\ny_train = df_train['total_amount']\n\n# create a K-Nearest Neighbors regression model.\nknn = KNeighborsRegressor()\n\n# define a grid of hyperparameter values to search over. in this case, it's the number of neighbors (n_neighbors) for the KNN model.\nparam_grid = {'n_neighbors': [1, 3, 5, 7, 10, 15, 20]}  # Adjust the values as needed\n\n# create a GridSearchCV object, specifying the KNN model, the parameter grid, \n# the scoring metric (r-squared in this case), and the number of cross-validation folds.\ngrid_search = GridSearchCV(knn, param_grid, scoring=make_scorer(r2_score), cv=5)\n\n# fit the GridSearchCV object to the training data. \n# this will perform an exhaustive search over the specified hyperparameter values and evaluate the model performance using cross-validation.\ngrid_search.fit(X_train, y_train)\n\n# print the best parameters found by grid search\nprint(\"best params:\", grid_search.best_params_)'''","metadata":{"execution":{"iopub.status.busy":"2023-12-15T06:47:45.672189Z","iopub.execute_input":"2023-12-15T06:47:45.672738Z","iopub.status.idle":"2023-12-15T06:52:52.884110Z","shell.execute_reply.started":"2023-12-15T06:47:45.672692Z","shell.execute_reply":"2023-12-15T06:52:52.882580Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"best params: {'n_neighbors': 3}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"best params: {'n_neighbors': 3} (KNN REGRESSOR)","metadata":{}},{"cell_type":"markdown","source":"***KNN REGRESSION***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\n\n# loading the training data\ndf_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T07:51:08.099105Z","iopub.execute_input":"2023-12-15T07:51:08.100573Z","iopub.status.idle":"2023-12-15T07:51:08.863753Z","shell.execute_reply.started":"2023-12-15T07:51:08.100503Z","shell.execute_reply":"2023-12-15T07:51:08.862138Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# data preprocessing and filling the missing values with the mean\nnum_cols = df_train.select_dtypes(include=['number']).columns\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].mean())\n\n# feature engineering (similar to the one hyperparameter tuning) \n# convert 'tpep_pickup_datetime' to datetime format and create new features based on the pickup time\ndf_train['tpep_pickup_datetime'] = pd.to_datetime(df_train['tpep_pickup_datetime'])\ndf_train['hour_of_day'] = df_train['tpep_pickup_datetime'].dt.hour\ndf_train['day_of_week'] = df_train['tpep_pickup_datetime'].dt.dayofweek\n\n# encoding categorical variables\ndf_train = pd.get_dummies(df_train, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T07:51:11.975268Z","iopub.execute_input":"2023-12-15T07:51:11.975802Z","iopub.status.idle":"2023-12-15T07:51:12.255636Z","shell.execute_reply.started":"2023-12-15T07:51:11.975754Z","shell.execute_reply":"2023-12-15T07:51:12.254172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# splitting the data set into features (x) and target (y)\nX_train = df_train.drop(columns=['total_amount', 'tpep_pickup_datetime', 'tpep_dropoff_datetime'])\ny_train = df_train['total_amount']\n\n# Itraining and initializing the the model (knn regressor here)\nmodel = KNeighborsRegressor(n_neighbors=3)  #from grid search parameters we know its 3\nmodel.fit(X_train, y_train)\n\n# predictions on the training dataset\npredictions_train = model.predict(X_train)\n\n# evaluating the r2 score of the model on the training set\nr2_train = r2_score(y_train, predictions_train)\nprint(f\"r2 score on training set: {r2_train}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T07:51:19.036442Z","iopub.execute_input":"2023-12-15T07:51:19.036956Z","iopub.status.idle":"2023-12-15T07:52:34.324297Z","shell.execute_reply.started":"2023-12-15T07:51:19.036911Z","shell.execute_reply":"2023-12-15T07:52:34.323117Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"r2 score on training set: 0.9047264234032898\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading the test data\ndf_test = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv')\n\n# data preprocessing for test data, and filling in the mean for missing values\nnum_cols_test = df_test.select_dtypes(include=['number']).columns\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].mean())\n\n# feature engg - test data\ndf_test['tpep_pickup_datetime'] = pd.to_datetime(df_test['tpep_pickup_datetime'])\ndf_test['hour_of_day'] = df_test['tpep_pickup_datetime'].dt.hour\ndf_test['day_of_week'] = df_test['tpep_pickup_datetime'].dt.dayofweek\ndf_test = pd.get_dummies(df_test, columns=['store_and_fwd_flag', 'payment_type'], drop_first=True)\n\n# same columns as training\nX_test = df_test[X_train.columns]\n\n# predictions on the test set\npredictions_test = model.predict(X_test)\n\n# dataframe for predictions\ntest_ids = pd.Series(range(1, len(predictions_test) + 1))\ndf_predictions = pd.DataFrame({'ID': test_ids, 'total_amount': predictions_test})","metadata":{"execution":{"iopub.status.busy":"2023-12-15T07:53:09.121863Z","iopub.execute_input":"2023-12-15T07:53:09.122345Z","iopub.status.idle":"2023-12-15T07:53:31.956039Z","shell.execute_reply.started":"2023-12-15T07:53:09.122293Z","shell.execute_reply":"2023-12-15T07:53:31.954549Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"'''\n# SAVING THE FILE TO SUBMISSION.CSV\ndf_predictions.to_csv('submission.csv', index=False)'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"r2 score on training set: 0.9047264234032898 (KNN REGRESSOR)\n\nScore in competition: 0.77772","metadata":{}},{"cell_type":"markdown","source":"**SUMMARY**\n\nGradient boosting is the best performing model till now. With moderate performance in knn regression (but not enough to pass the cutoff) and average in linear regression \n\nThe reason why linear regression is getting low r2 scores is because it assumes linear relationship between features and target variable. And the true relationship, it seems so, is non-linear. In contrast, both KNN and gradient boosting are flexible and can model non-linear models effectively.\n\nOther fact is linear regression is sensitive to quality of feature engineering, while the other two are very much able to adapt.\n\nAs to why KNN r2 score is lower than gradient boosting, is due to the parameter tuning in KNN. It is highly dependent on the choice of hyperparameters (no. of neighbours), if the value of that is not optimized enough, it can impact model's performance. So there's  scope of improvement in generalization. \n\nIn gradient boosting, adjusting the hyperparameters is helping us reduce overfitting of the data. Also it is more capable than KNN in terms of robustness to noise and handling complex relationships. It is an ensemble method, i.e it combines multiple weak learners (usually decision trees) to improve predictive performance compared to individual models, and this can lead to a higher r2 score. ","metadata":{}}]}